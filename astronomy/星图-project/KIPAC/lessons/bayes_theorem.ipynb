{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayes Theorem\n",
    "\n",
    "Goals:\n",
    "* Grasp how the mathematics of probability can be used to do statistical inference.\n",
    "* Start working through real inference problems, with pencil, paper, and PGMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exec(open('code/bayes_theorem.py').read()) # see code here for later demos\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* Gelman ch. 1\n",
    "* Ivezic 5.1-5.3\n",
    "* MacKay 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sampling distributions and likelihoods\n",
    "\n",
    "You've just been introduced to PGMs, which provide a visual representation of how data are generated.\n",
    "\n",
    "* In inference problems, we have one (and only one) dataset to learn from\n",
    "\n",
    "* The sampling distribution, $p(\\mathrm{data}|\\mathrm{params})$, plays a central role, since it quantifies how probable a given data set is given an assumed set of parameters.\n",
    "\n",
    "* When evaluated as a function of the parameters, $p(\\mathrm{data}|\\mathrm{params})$ is known as the **likelihood function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Likelihood gotchas\n",
    "\n",
    "* The sampling distribution is a PDF, normalized in data space\n",
    "\n",
    "* The likelihood function is _not_ not a PDF for the parameters - it's not normalized in parameter space\n",
    "\n",
    "* Either way, PGMs are still useful for visualizing the factorization of a joint probability into conditionally independent pieces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PGMs in inference\n",
    "\n",
    "<img src=\"graphics/pgms_all_pixels_input_sampled_inverse.png\" width=60%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Double circled (or, sometimes, gray shaded) nodes denote variables that are _fixed by observation_: these nodes indicate the data.\n",
    "\n",
    "* The PGM still illustrates a particular factorization of the joint PDF of all variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<img src=\"graphics/pgms_all_pixels_input_sampled_inverse.png\" width=30%>\n",
    "\n",
    "* $\\theta \\sim$ ???\n",
    "* For each $k$:\n",
    "  * $\\mu_k|\\theta =$ ???\n",
    "  * $N_k|mu_k \\sim$ ???\n",
    "  \n",
    "$P(\\theta) \\prod_k P(\\mu_k|\\theta) P(N_k|\\mu_k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other ingredients for principled inference\n",
    "\n",
    "$p($data|params$)$ clearly has a role to play in inferring which parameter values are consistent with the data. What else do we need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* $p($params$)$, the **prior distribution**\n",
    "* $p($params|data$)$, the **posterior distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The prior distribution\n",
    "\n",
    "$p($params$)$\n",
    "* The *marginal* probability of a set of parameter values (integrated over possible data sets).\n",
    "* Consequently, *independent of the measured data*.\n",
    "* Interpretation: what we know about the model parameters *before* incorporating new knowledge in the form of the measured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The posterior distribution\n",
    "\n",
    "$p($params|data$)$\n",
    "* The probability of a model *given* the measured data.\n",
    "* Interpretation: what we know about the model parameters *after* incorporating new knowledge in the form of the measured data. In other words, the product of statistical inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes Theorem\n",
    "The ingredients above are all related through the definition of conditional probability\n",
    "\n",
    "$p(\\mathrm{params}|\\mathrm{data}) = \\frac{p(\\mathrm{data}|\\mathrm{params})\\,p(\\mathrm{params})}{p(\\mathrm{data})}$\n",
    "\n",
    "The crux of this theorem, what makes it more than a trivial restatement, is that probability distributions are the appropriate mathematical tool for encoding knowledge about models and parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* $p(\\mathrm{params})$: prior - what we know before doing the experiment\n",
    "* $p(\\mathrm{data}|\\mathrm{params})$: sampling distribution - probability of obtaining our data set\n",
    "* $p(\\mathrm{params}|\\mathrm{data})$: posterior - what we know after doing the experiment (\"the answer\")\n",
    "* $p(\\mathrm{data})$: evidence - marginal probability of obtaining our data for any parameter values (more on this later)\n",
    "\n",
    "All of these terms are implicitly also conditional on the _choice of model_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### PGMs and Bayes\n",
    "\n",
    "* There are two ways of factorizing the joint PDF for all variables:\n",
    "\n",
    "$p(\\mathrm{params}, \\mathrm{data}) = p(\\mathrm{params}|\\mathrm{data}) \\, p(\\mathrm{data})$\n",
    "\n",
    "$= p(\\mathrm{data}|\\mathrm{params}) \\, p(\\mathrm{params})$\n",
    "\n",
    "* The second one is the factorization illustrated by the PGM - and it is proportional to the posterior PDF for the parameters given the data.\n",
    "\n",
    "* PGMs help us _design inferences_, by illustrating the conditional dependencies between parameters and data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: measuring the flux of a source\n",
    "\n",
    "Say we want to measure the flux of a galaxy. In a given integration time, $T$, the number of counts, $N$, that we collect in our fancy CCD will be Poisson distributed\n",
    "\n",
    "$N|\\mu \\sim \\mathrm{Poisson}(\\mu)$\n",
    "\n",
    "where $\\mu=FAT$ is the average number of counts we would expect in time $T$, the product of the integration time, the source flux ($F$, counts per unit time and area), and the collecting area of our telescope ($A$).\n",
    "\n",
    "Presumably we know $A$ and $T$ well, so for convenience we can make $\\mu$ rather than $F$ the free parameter of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$N|\\mu \\sim \\mathrm{Poisson}(\\mu)$\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"graphics/bayes_poissoneg_likelihood.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$N|\\mu \\sim \\mathrm{Poisson}(\\mu)$\n",
    "\n",
    "$\\mu \\sim \\mathrm{some~prior}$\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"graphics/bayes_poissoneg_pgm0.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll talk more about how to choose a prior in a few minutes. For now, we'll make a common choice, the uniform distribution (for $\\mu\\geq0$ in this case).\n",
    "* This is an **improper** distribution, i.e. one that can't technically be normalized. This doesn't necessarily matter, as long as the posterior distribution turns out to be proper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\mu \\sim \\mathrm{Uniform}(0,\\infty)$\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"graphics/bayes_poissoneg_prior.png\" width=75%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What about the evidence, $P(N)$?\n",
    "* This is constant with respect to model parameters by definition, so we don't actually need to calculate it (although we could, by marginalizing the sampling distribution over $\\mu$).\n",
    "* That's because we know the posterior will be a probability distribution - as long as it's proper, the normalizing constant must be whatever makes it integrate to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So, we have everything we need to calculate $p(\\mu|N)\\propto P(N|\\mu)p(\\mu)$.\n",
    "\n",
    "Say we measure $N=5$. Now what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Broadly speaking, we have 3 options for computing the posterior.\n",
    "* Brute force over a grid in parameter space: straightforward, but expensive in many dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Analytically: super-efficient, but only possible for certain forms of the likelihood and prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Monto Carlo: a more intelligent brute-force method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Brute force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 5\n",
    "mu = np.linspace(0.0, 20.0, 100) # np == numpy\n",
    "prior = 1.0                      # uniform (proportional to a constant)\n",
    "like = st.poisson.pmf(N, mu)     # st == scipy.stats\n",
    "post = like * prior\n",
    "plt.rcParams['figure.figsize'] = (6.0,4.0) # plt == matplotlib.pyplot\n",
    "plt.plot(mu, post, 'bo');\n",
    "plt.plot([N]*2, [0.0, np.max(post)*1.1], 'k--');\n",
    "plt.xlabel(r'$\\mu$', fontsize=22);\n",
    "plt.ylabel('posterior', fontsize=22);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Analytical solution\n",
    "\n",
    "If both the prior and likelihood are built from standard statistical distributions, we can sometimes take advantage of [conjugacy](https://en.wikipedia.org/wiki/Conjugate_prior).\n",
    "\n",
    "**Conjugate distributions** are like eigenfunctions of Bayes Theorem. These are special cases for which the form of the posterior is the same as the prior, for a specific sampling distribution.\n",
    "\n",
    "$f(x|\\theta)g(\\theta|\\phi) = g\\left[\\theta\\left|\\tilde{\\phi}(x,\\phi)\\right.\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Poisson distribution is conjugate to the Gamma distribution\n",
    "\n",
    "$p(x|\\alpha,\\beta) = \\frac{1}{\\Gamma(\\alpha)}\\beta^\\alpha x^{\\alpha-1} e^{-\\beta x}$ for $x\\geq0$\n",
    "\n",
    "Our uniform prior is a limiting case of Gamma (with $\\beta\\rightarrow0$), so we can take advantage of this.\n",
    "\n",
    "If we take the prior $\\mu \\sim \\mathrm{Gamma}(\\alpha_0,\\beta_0)$, the posterior will be $\\mu|N \\sim \\mathrm{Gamma}(\\alpha_0+N,\\beta_0+1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"graphics/bayes_poissoneg_pgm.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here we can demo how the posterior distribution depends on these prior **hyperparameters**, as well as the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8.0,5.0)\n",
    "# returns alpha,beta describing the posterior\n",
    "bayesDemo(alpha0=1.0, beta0=0.001, N=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayes theorem as a model for accumulating information\n",
    "\n",
    "$p(\\mathrm{params}|\\mathrm{data}) = \\frac{p(\\mathrm{data}|\\mathrm{params})\\,p(\\mathrm{params})}{p(\\mathrm{data})}$\n",
    "* Within this formalism, today's posterior becomes tomorrow's prior seamlessly.\n",
    "\n",
    "Assuming independent measurements, $p(\\theta|x_1,x_2) \\propto p(x_2|\\theta)p(x_1|\\theta)p(\\theta) = p(x_2|\\theta)p(\\theta|x_1)$\n",
    "* We can try this out with the demo on the previous slide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise: categorizing galaxy clusters\n",
    "\n",
    "X-ray imaging data for 361 galaxy clusters were analyzed, and 57 of them were found to be morphologically \"relaxed\" according to some metric (arxiv:[1502.06020](https://arxiv.org/abs/1502.06020)). We want to constrain the fraction of relaxed clusters in the Universe (the probability that a randomly chosen cluster is relaxed), $f$, assuming that the data set is representative.\n",
    "\n",
    "1. What sampling distribution is associated with this type of categorical data?\n",
    "2. What prior distribution is nicely conjugate to it? (Look this up.) Choose hyperparmeters corresponding to a broadly reasonable prior (e.g. uniform).\n",
    "3. Sketch a PGM for this experiment, and write down the corresponding conditional probability expressions.\n",
    "4. Prove the conjugacy relation for the sampling and prior distributions above. (This does not require integration.)\n",
    "5. Write down the posterior for $f$. What is the most probable value for $f$? You can consult a reference for the mode of the appropriate distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing a prior\n",
    "\n",
    "The prior distribution encodes \"what we know before doing the experiment at hand\".\n",
    "* Things are straightforward if we have prior knowledge from e.g. previous measurements or trustworthy simulations, and don't mind including it in our analysis.\n",
    "* Otherwise, one generally assigns an \"uninformative\" prior.\n",
    "* But note that **no distribution is truly devoid of information**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### \"Uninformative\" priors\n",
    "\n",
    "Common choices are\n",
    "* Uniform\n",
    "* Uniform in the log (i.e. in the order of magnitude)\n",
    "* The [Jeffreys prior](https://en.wikipedia.org/wiki/Jeffreys_prior) for a given problem, which provides minimal Fisher information\n",
    "* Priors with [maximal entropy](https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution) for a given problem\n",
    "\n",
    "The last 2 are not seen as often in astrophysics, but are worth knowing about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Again, **there is no genuinely uninformative option**. At best, we can make a minimally informative and defensible choice that doesn't significantly influence the result.\n",
    "* If the data are so inadequate that out choice of prior really matters, our job as analysts is to clearly state/defend our assumptions and their influence on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise: defend a prior\n",
    "\n",
    "Given the choice between uniform, uniform-in-the-log ($\\propto1/x$), or some other prior of your choosing on the following measurables, what do you think is most appropriate?\n",
    "\n",
    "* The height of a classmate\n",
    "* The mass of a star\n",
    "* The mass of a _neutron_ star\n",
    "* The distance to a supernova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing posterior distributions\n",
    "\n",
    "The posterior for model parameters may be \"the answer\" to an inference problem, but we often want a summary of the form $\\theta = \\theta_0 \\pm \\Delta\\theta$ or $\\theta_0{}_{-\\Delta\\theta_m}^{+\\Delta\\theta_p}$.\n",
    "* This is interpreted as a statement about the *marginal* posterior of $\\theta$, namely that $\\theta$ is in the given **credible interval** with some (specified) probability.\n",
    "* Note that credible intervals are technically different from the confidence intervals that appear in non-Bayesian statistics, but in practice the terms are often used interchangeably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are several conventions in use for how to come up with a best estimate and credible interval:\n",
    "* Most-probable value and interval (most intuitive)\n",
    "* Median and symmetric percentiles (easy)\n",
    "* Mean and symmetric interval (huh?)\n",
    "\n",
    "And some things you probably shouldn't do (valid only in certain limits)\n",
    "* Mean and standard deviation\n",
    "* Intervals from differences in log-likelihood (or log-posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1 . Most-probable value and interval\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"graphics/bayes_ci_maxp.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2 . Median and symmetric percentiles\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"graphics/bayes_ci_perc.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3 . Mean and symmetric interval\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"graphics/bayes_ci_mean.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Differences between the conventions can be pronounced in the case of limits.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"graphics/bayes_ci_limit_maxp.png\" width=100%></td>\n",
    "        <td><img src=\"graphics/bayes_ci_limit_perc.png\" width=100%></td>\n",
    "        <td><img src=\"graphics/bayes_ci_limit_mean.png\" width=100%></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>most probable</td>\n",
    "        <td>median/percentiles</td>\n",
    "        <td>mean/symmetric</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Joint constraints (contours) for multiple parameters work similarly, although here only the maximum-probability approach is in wide use.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"graphics/straightline_2d_post.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Everything in this course is an inference\n",
    "\n",
    "We've focussed on one task so far, but this framework applies any time we want to draw a conclusion from data.\n",
    "* constraining model parameters\n",
    "* choosing between model frameworks\n",
    "* source detection\n",
    "* interpolation and extrapolation\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus numerical exercise: conjugate distributions\n",
    "\n",
    "Adapt the code in [bayes_theorem.py](../code/bayes_theorem.py) and above for the \"flux of a source\" demo to produce an equivalent demo for the \"relaxed galaxy cluster\" example. It should take as input the prior hyperparameters and data (number of relaxed clusters and total number of clusters), produce plots of the prior and posterior (optionally also the likelihood), and return the parameters describing the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus numerical exercise: independent monte carlo\n",
    "\n",
    "So far, we've used examples where the posterior is a standard distribution. In general this is not the case, and we resort to methods which produce **samples** from the posterior in order to estimate its density and/or integrate it (e.g. to marginalize some parameters). Sampling can be useful even in simple cases, especially for downstream propagation of uncertainties. This exercise will get you some practice working with `scipy`, and introduce the simplest possible sampling method.\n",
    "\n",
    "For either the Poisson or Binomial examples above, make up some reasonable data and generate $10^4$ samples from the posterior distribution. Then do some post-processing:\n",
    "1. For the Poisson experiment, convert the posterior for $\\mu$ (average number of counts) into something akin to magnitude. Simplifying away things like the reference, integration time and collecting area, use the formula $m=1-2.5\\log_{10}(\\mu/50)$.\n",
    "2. For the Binomial experiment, *predict* the number of relaxed clusters found in a hypothetical much larger sample (say 5000 clusters in total). That is, generate a Poisson sample from each of the samples of $\\mu=5000f$ corresponding to the larger sample size.\n",
    "\n",
    "Visualize the distributions for these derived parameters by plotting histograms of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus numerical exercise: confidence intervals\n",
    "\n",
    "Write a function for determining the maximum-probability best fit and 1-dimensional confidence interval at a given level from an array of samples. (You can also write one that takes a posterior function as input instead of samples, but in the future we'll be using samples a lot.) Note that some kind of intelligent smoothing or kernel density estimation is generally needed to suppress numerical noise in histograms. Feel free to do the same for the percentile-based confidence intervals described above.\n",
    "\n",
    "MegaBonus: Write a function for generating 2-dimensional confidence contours the same way. (Note that the `corner` package provides a nifty way to do this already.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
