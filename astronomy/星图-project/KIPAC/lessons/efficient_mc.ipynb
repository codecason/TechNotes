{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Efficient Monte Carlo Sampling\n",
    "\n",
    "Goals:\n",
    "* Introduce some of the approaches used to make sampling more efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* Gelman chapters 11 and 12\n",
    "* Ivezic 5.8\n",
    "* MacKay chapters 29-30\n",
    "* Handbook of MCMC (Brooks, Gelman, Jones and Meng, eds.), parts of which are [on the web](http://www.mcmchandbook.net/HandbookTableofContents.html)\n",
    "* [Recent](http://arxiv.org/abs/1304.4473) and [less recent](http://cosmologist.info/notes/MCMC.ppt) notes on `CosmoMC` by Antony Lewis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation\n",
    "\n",
    "Quite often, repeated evaluation of the posterior function becomes a bottleneck. Any tweaks that speed up convergence and reduce autocorrelation can be worthwhile.\n",
    "\n",
    "The simple methods introduced so far especially struggle with\n",
    "* strongly degenerate parameter combinations\n",
    "* PDFs with multiple, separated modes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some strong degeneracies:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            Cosmology is bananas<br>\n",
    "            <a href=\"graphics/mc2_banana_eg.source\"><img src=\"graphics/mc2_banana_eg.png\" width=100%></a>\n",
    "        </td>\n",
    "        <td></td>\n",
    "        <td>\n",
    "            The Rosenbrock function<br>\n",
    "            <a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_rosenbrock.png\" width=100%></a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some multiple modes:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            Some spectral model<br>\n",
    "            <a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_multimode_eg2.png\" width=100%></a>\n",
    "        </td>\n",
    "        <td></td>\n",
    "        <td>\n",
    "            The eggbox function<br>\n",
    "            <a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_eggbox.png\" width=100%></a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Speeding things up\n",
    "\n",
    "Broadly speaking, we can try to\n",
    "1. tailor algorithms to specific classes of PDF\n",
    "2. look for ways to make the general samplers more intelligent\n",
    "\n",
    "We can also use different samplers for different subsets of parameters - the only rule is that every parameter must get updated somehow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gibbs Sampling\n",
    "is a specialization of Metropolis-Hastings:\n",
    "* Instead of making a general proposal, we cycle through the parameters proposing changes to one at a time\n",
    "* A proposal for $\\theta_i$ is into the **fully conditional posterior** $p(\\theta_i|\\theta_{-i},x)$, where $-i$ means all subscripts other than $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gibbs sampling:\n",
    "```\n",
    "while we want more samples\n",
    "    propose theta1 | theta2, theta3, ..., data\n",
    "    accept/reject theta1\n",
    "    propose theta2 | theta1, theta3, ..., data\n",
    "    accept/reject theta2\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In general, this is not obviously an improvement to proposing changes to all $\\theta$ simultaneously.\n",
    "\n",
    "**But**, something interesting happens if the fully conditional likelihood and prior are conjugate - then we know the conditional posterior exactly. If we use independent samples of the conditional posterior as proposals, then the Metropolis-Hastings acceptance ratio becomes\n",
    "\n",
    "$\\frac{p(y|\\theta_{-i})Q(x|y,\\theta_{-i})}{p(x|\\theta_{-i})Q(y|x,\\theta_{-i})} = \\frac{p(y|\\theta_{-i})p(x|\\theta_{-i})}{p(x|\\theta_{-i})p(y|\\theta_{-i})} = 1$\n",
    "\n",
    "and every proposal is automatically accepted!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Conjugate Gibbs Sampling:\n",
    "```\n",
    "while we want more samples\n",
    "    draw th1 from p(th1|th2,th3,...,data)\n",
    "    draw th2 from p(th2|th1,th3,...,data)\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: normal PDF\n",
    "\n",
    "25 Metropolis iterations (left) vs. 25 Gibbs transitions (right)\n",
    "\n",
    "Color goes blue$\\rightarrow$red with time (step number)\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_metro.png\" width=100%></a>\n",
    "        </td>\n",
    "        <td></td>\n",
    "        <td>\n",
    "            <a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_gibbs.png\" width=100%></a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gibbs Sampling Pros:\n",
    "* No cycles \"wasted\" on rejected proposals\n",
    "* No pesky tuning of the proposal scale\n",
    "\n",
    "Gibbs Sampling Cons:    \n",
    "* Only works for conjugate or partially conjugate models (hence must choose conjugate priors)\n",
    "* Occasionally still slower than proposing multi-parameter Metropolis updates (e.g. when degeneracies are strong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are some packages that can figure out what conjugate relationships exist based on a model definition, and do Gibbs sampling.\n",
    "* [BUGS](http://openbugs.net/w/FrontPage)\n",
    "* [JAGS](http://mcmc-jags.sourceforge.net/)\n",
    "\n",
    "(See also our [list of MCMC packages](../doc/MCMC_packages.md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: normal likelihood\n",
    "\n",
    "Suppose we have some data, $x_i$, that we're modelling as being generated by a common normal distribution.\n",
    "\n",
    "$p(x_i|\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\,\\exp-\\frac{(x_i-\\mu)^2}{2\\sigma^2}$\n",
    "\n",
    "The model parameters are the mean, $\\mu$, and variance, $\\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consulting [the Wikipedia](https://en.wikipedia.org/wiki/Conjugate_prior), we see that we can Gibbs sample this posterior using two steps:\n",
    "* the conjugate distribution for $\\mu|\\sigma^2,x$ is normal\n",
    "* the conjugate distribution for $\\sigma^2|\\mu,x$ is scaled inverse $\\chi^2$\n",
    "\n",
    "Remember that using conjugacy limits our options for choosing priors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Slice sampling\n",
    "\n",
    "A less specialized modification of Metropolis-Hastings is **slice sampling**. This method also reduces the need to manually tune a proposal scale, although it usually involves a rejection step.\n",
    "\n",
    "Given a starting point, $\\theta_0$, we uniformly choose a probability $q\\leq p(\\theta_0)$. This defines a *slice* where $p(\\theta)\\geq q$, and we sample the next $\\theta$ uniformly within the slice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_slice.png\" width=75%></a></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How to do this without actually mapping out the PDF?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "See also [Neal 2003](https://dx.doi.org/10.1214%2Faos%2F1056562461)\n",
    "\n",
    "```\n",
    "start with position x\n",
    "evaluate p = P(x)\n",
    "guess a width W\n",
    "while we want samples\n",
    "    draw q from Uniform(0,p)\n",
    "    choose L,R: R-L=W and L<=x<=R\n",
    "    while P(L) > q, set L = L - W\n",
    "    while P(R) > q, set R = R + W\n",
    "    loop forever\n",
    "        draw y from Uniform(L,R)\n",
    "        if P(y) < q,\n",
    "            if y < x, set L = x1\n",
    "            otherwise, set R = x1\n",
    "        otherwise, break\n",
    "    set x = x1 and record x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_slice2.png\" width=75%></a></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Slice Sampling Pros:\n",
    "* Tends to need fewer evaluations per move than Metropolis with a poorly tuned proposal scale\n",
    "\n",
    "Slice Sampling Cons:\n",
    "* Tends to need more evaluations per move than Metropolis with a well tuned proposal scale\n",
    "\n",
    "Slicing can be a nice option for \"test chains\" intended to explore the parameter space, find the high-posterior region, and roughly probe its covariance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accelerating Metropolis\n",
    "\n",
    "The simple Metropolis implementation introduced in our [Tutorial](../tutorials/Week3/Metropolis.ipynb) lesson can be improved on in a number of ways. Recall:\n",
    "\n",
    "```choose a starting point and a proposal scale\n",
    "while we want more samples\n",
    "    propose a new point from a scaled Gaussian\n",
    "      centered on our current position\n",
    "    accept/reject the new point\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These strategies often boil down to cleverly, and automatically, tuning our proposal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Strictly speaking, tuning the proposal distribution on the fly breaks the rules of MCMC (specifically, detailed balance).\n",
    "* Technically, we *should* stop tuning after some time and throw away all steps before this point.\n",
    "* In practice, if we've actually managed to converge to the target distribution, subsequent updates to the proposal distribution will be negligible anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Intelligent proposal lengths\n",
    "\n",
    "A Gaussian proposal distribution makes the most likely proposals very near the current point. This is not necessarily efficient. We could instead\n",
    "\n",
    "* propose a step length from a heavier-tailed distribution\n",
    "* tune the scale of the proposed move based on the acceptances so far (our estimate of the width of the posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A non-Gaussian proposal distribution to encourage larger steps:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_steplength.png\" width=75%></a></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tuning the proposal basis\n",
    "\n",
    "Parameter degeneracies are inconvenient.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><a href=\"graphics/montecarlo1.R\"><img src=\"graphics/mc1_sandbox_ab.png\" width=75%></a></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Degeneracies can usually be reduced or eliminated by reparametrizing the model.\n",
    "* But beware - a nonlinear reparametrization does not leave your prior invariant - recall the transformation of PDFs.\n",
    "* Linear reparametrizations are equivalent to a change of basis for the parameter space. To gain the benefits of this, we merely need to change the way we propose steps (which can be done automatically)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><H2>Original</H2><br><a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_reparam0.png\" width=100%></a></td>\n",
    "        <td><H2>Parameter basis change</H2><br><a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_reparam1.png\" width=100%></a></td>\n",
    "        <td><H2>Proposal basis change</H2><br><a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_reparam2.png\" width=100%></a></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For a nice, elliptical PDF, the optimal basis diagonalizes the covariance of the parameters.\n",
    "* This doesn't mean we can only propose along the preferred directions.\n",
    "* It does mean that, in a given direction, we know the optimal length scale for the proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fast-slow decompositions\n",
    "If changes to some parameters require much more costly calculations than others, straightforward diagonalization may not be optimal in practice.\n",
    "* We can choose to propose changes to fast parameters more often than slow parameters.\n",
    "* Given a hierarchy of speeds, we can also *triangularize* the covariance matrix - so the fastest parameter appears in every basis vector and the slowest only in one.\n",
    "* ... ad nauseam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><h2>Original</h2><br><a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_reparam0.png\" width=100%></a></td>\n",
    "        <td><h2>Diagonalized covariance</h2><br><a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_reparam2.png\" width=100%></a></td>\n",
    "        <td><h2>Triangular fast-slow</h2><br><a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_reparam3.png\" width=100%></a></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Running multiple chains\n",
    "Unless we know what to do a priori, the best information for how to tune proposal lengths and directions comes from running test chains started from different positions and using the information they build up about the posterior.\n",
    "\n",
    "Parallel, communicating chains (e.g. using MPI) that tune themselves this way can **vastly** decrease the time to convergence compared with single chains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Information about the principal axes shows up relatively quickly, and more quickly if we look at more than 1 chain.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><a href=\"graphics/montecarlo1.R\"><img src=\"graphics/mc1_sandbox_ab.png\" width=100%></a></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's an example of adaptive Metropolis sampling of a highly degenerate 2D Gaussian ($\\rho=0.99$). The start points are dispersed, and one happens to fall quite near the degenerate axis.\n",
    "\n",
    "[Case 1](graphics/notparallel_chain_fit.py) has 4 chains that adapt independently of one another by diagonalizing the parameter covariance every 100 steps.\n",
    "\n",
    "[Case 2](graphics/parallel_chain_fit.py) is the same, except that the chains pool their knowledge of the parameter covariance when adapting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_parallel_xy1.png\" width=100%></a></td>\n",
    "        <td><a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_parallel_xy2.png\" width=100%></a></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Independent, adaptive chains\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_parallel_trace1.png\" width=100%></a></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Communicating, adaptive chains\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_parallel_trace2.png\" width=100%></a></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tempering\n",
    "Consider the function $[p(x)]^{1/T}$, where $p(x)$ is the target PDF.\n",
    "* We say a chain sampling this function has temperature $T$. For $T>1$, $p^{1/T}$ is smoothed out compared with $p$ (cf simulated annealing).\n",
    "* This allows chains to move among multiple peaks more easily.\n",
    "* Of course, we're only actually interested in $T=1$..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parallel tempering\n",
    "\n",
    "With parallel tempering, we run one chain with $T=1$ and several more chains with $T>1$. A modified Metropolis-Hastings update occasionally allows the chains to exchange positions, giving the $T=1$ chain a mechanism for sampling regions of parameter space it might otherwise have low probability of proposing. Samples from the $T=1$ chain can be used for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise: think\n",
    "\n",
    "Recall the ugly PDF features we were motivated by, namely strong/nonlinear degeneracies and multiple modes.\n",
    "For each of the methods above, do you expect an improvement compared with standard Metropolis in these situations. Why and for which methods?\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_rosenbrock.png\" width=80%></a>\n",
    "        </td>\n",
    "        <td></td>\n",
    "        <td>\n",
    "            <a href=\"graphics/montecarlo2.R\"><img src=\"graphics/mc2_eggbox.png\" width=80%></a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coping with multiple modes\n",
    "\n",
    "Multiple, well separated posterior modes are a serious challenge for many samplers.\n",
    "* In general, the only way to discover that they exist is by exploring the parameter space with many widely dispersed chains.\n",
    "* To do inference, our chains need to be able to efficiently transition between modes - so far the most reliable general method we've seen for this is parallel tempering. (We'll look at others later.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus numerical exercise: play\n",
    "\n",
    "Play around with sampling these 4 difficult PDFs (coded below):\n",
    "1. The Rosenbrock function (actually minus this; it's normally used for testing minimizers), illustrated above\n",
    "2. The eggbox function, illustrated above\n",
    "3. A spherical shell function\n",
    "4. A Gaussian PDF (suitable for Gibbs sampling)\n",
    "\n",
    "First, see how well simple Metropolis works, or doesn't work. Then choose one of the speed-ups above and modify/replace the sampler to use it on one or more of these PDFs. Compare performance (burn-in length, acceptance rate, etc.) with simple Metropolis. (Apart from PDF 4, chances are that nothing you do will work brilliantly, but you should see a difference!)\n",
    "\n",
    "For Gibbs sampling, interpret PDF 4 as a likelihood function and put some thought into how you define your priors. Otherwise, just take the given PDF to be the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Rosenbrock_lnP(x, y, a=1.0, b=100.0):\n",
    "    if y < 0.0: return -np.inf\n",
    "    return -( (a-x)**2 + b*(y-x**2)**2 )\n",
    "def eggbox_lnP(x, y):\n",
    "    return (2.0 + np.cos(0.5*x)*np.cos(0.5*y))**3\n",
    "def sphshell_lnP(x, y, s=0.1):\n",
    "    return -(np.sqrt(x**2+y**2) - 1)**2/(2.0*s**2)\n",
    "gaussian_data = np.random.normal(size=(20)) # arbitrary data set\n",
    "def gaussian_lnP(m, v):\n",
    "    if v <= 0.0: return -np.inf\n",
    "    return -0.5*np.sum((m-gaussian_data)^2)/v - 0.5*np.log(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
