{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMINDERS\n",
    "\n",
    "#### Submitting your homework\n",
    "\n",
    "Before doing **anything**,\n",
    "\n",
    "1. **Make a copy** of this notebook in your clone of the [**private** course repository](https://github.com/abmantz/phys366_2019). Edit that copy, not the version in the public repository clone. Please *follow the instructions in the [private repo README](https://github.com/abmantz/phys366_2019/blob/master/README.md)* by locating your solutions on a path like `phys366_2019/HW_week<N>/<Your Name(s)>/` and note that *case matters*. Take a minute to look hard at the directory structure and choose your filenames carefully: if your solutions are not in the right place they will not be graded.\n",
    "\n",
    "2. Remember that you will submit your solution by pull request to the **private** repository.\n",
    "\n",
    "#### Submitting your project plan and PGM\n",
    "\n",
    "This week you also need to produce a **project plan and PGM**. As explained in the [\"Project Milestones\" instructions](https://github.com/KIPAC/StatisticalMethods/blob/master/doc/ProjectMilestones.md#plan-pgm):\n",
    "\n",
    "> _At this point, you should have an idea and a team that you expect to stick with. Your task this week is to submit a rough plan for what you aim to accomplish, i.e. the scope of the project, and a guess at when various things will be done. In addition, sketch a PGM for the model involved in your project._\n",
    "\n",
    "As with your homework solution, push your (team's) plan and PGM to your fork of the **private repo** in to a file named `phys366_2019/Project_milestones/<project name>/plan.ipynb` and submit a PR to the **private** repository. Writing your plan as a jupyter notebook is a good idea, so you can iterate on any PGM code you write later (or just use the notebook to display a graphics file of your PGM as part of your plan).\n",
    "\n",
    "#### Sending us feedback\n",
    "\n",
    "Once you've submitted your solution, don't forget to also fill out the very quick (and required!) **[weekly feedback form](https://docs.google.com/forms/d/e/1FAIpQLSfH0JGjJd67ANAOcUiRT54nmYtQHViKyOQe-20cny3GDytV6Q/viewform?usp=sf_link).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Week 5 Homework\n",
    "\n",
    "## Comparing Models\n",
    "\n",
    "In the [Week 5 Tutorial]() we developed machinery for _evaluating_ a simple model for our cluster mis-centering distance data. We will now re-use this machinery to compare the simple model we assumed in class (Model 1, $H_1$) with a more complex model of your design (Model 2, $H_2$), repeating the various fitting and evaluating steps that we did for Model 1 for this new model.\n",
    "\n",
    "> **_If you did not complete the tutorial in class, do so now, since this homework depends on it._**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Reproducing your Model1 results \n",
    "\n",
    "First of all, copy, or export and `%load` the code you wrote in the Tutorial into this notebook, so that you can reproduce the Tutorial Model 1 calculations here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 'large'\n",
    "plt.rcParams['ytick.labelsize'] = 'large'\n",
    "%matplotlib inline\n",
    "# or %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data to a global variable, as in the tutorial:\n",
    "y = np.loadtxt('../data/model_comparison.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit, uncomment and execute this cell to read in your tutorial code, downloaded as python from the notebook. \n",
    "# Then edit it to just contain the code you need.\n",
    "# %load phils_model_comparison_tutorial.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your machinery loaded in, re-do your evaluation of model 1 from the tutorial, step by step, and check that it reproduces your tutorial results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model1 = SimpleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples1 = Model1.draw_samples_from_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visual_check(Model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = posterior_predictive_check(Model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIC1, pD1 = DIC(Model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logE1 = log_evidence(Model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Model 2 specification\n",
    "\n",
    "Choose a more complex model to compare to Model 1 from the tutorial. A good strategy could be to use a _mixture_ of two standard PDFs (implemented in `scipy`) for the sampling distribution, with a parameter indicating the relative proportion of the two components, such that\n",
    "\n",
    "$P(y|\\theta_1,\\theta_2,f,H_2) = f\\,P_1(y|\\theta_1,H_2) + (1-f)\\,P_2(y|\\theta_2,H_2)$.\n",
    "\n",
    "But feel free to do something different if you like. You will also need to assign sensible prior PDFs for your model parameters $\\mathbf{a}$. Note that you will now have an array of parameters to infer. Notice that in the mixture model suggested above, $f$ is also a parameter of the model; in this case, you'd have $\\mathbf{a}=(\\theta_1,\\theta_2,f)$.\n",
    "\n",
    "Write out the formula for your model sampling distribution $P(\\mathbf{y}|\\mathbf{a},H_2)$, and for all the terms in the joint prior $P(\\mathbf{a}|H_2)$. Write a few sentences explaining your choices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Model 2:** $P(\\mathbf{y}|\\mathbf{a},H_2) = \\ldots$\n",
    "\n",
    "**Priors:**\n",
    "$P(\\mathbf{a}|H_2) = \\ldots$\n",
    "\n",
    "**Explanation:**\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Implementing your Model 2\n",
    "\n",
    "Now copy, extend, or sub-class `SimpleModel` to include implementations of the likelihood, posterior, and predictive functions for your Model 2. As in the tutorial, you'll want to do a few spot checks to make sure the class methods are doing what you want them to do. \n",
    "\n",
    "> NB. You'll be moving from 1D to multiple dimensions, so watch out for _array shape errors_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlternativeModel(object):\n",
    "    \"\"\"\n",
    "    Parameter inference and model evaluation in a more advanced cluster mis-centering analysis.\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fitting Model 2 to the data\n",
    "\n",
    "Characterize the posterior PDF for your model parameters $P(\\mathbf{a}|y,H_2)$ with a set of MCMC samples. \n",
    "The `emcee` sampling code from the tutorial should still work, with relatively minor changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model2 = AlternativeModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples2 = Model2.draw_samples_from_posterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Visually checking Model 2\n",
    "\n",
    "By generating an ensemble of replica datasets, carry out a visual posterior predictive check of Model 2.\n",
    "\n",
    "Does your new model appear to fit the data better than Model 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_check(Model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Posterior predictive check of Model 2 using a suitable test statistic\n",
    "\n",
    "In the tutorial you designed a test statistic $T(y)$ for use in a quantitative posterior predictive model check. Carry out the same check for Model 2, and report the probability $P(T > T(y)|y,H_2)$. Does your new model fit the data better than Model 1 in this regard?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = posterior_predictive_check(Model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Calculate the DIC and $p_D$ for Model 2\n",
    "\n",
    "Does the value of $p_D$ make sense? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIC2, pD2 = DIC(Model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Compute the evidence for Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logE2 = log_evidence(Model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Compare Model 2 and Model 1\n",
    "\n",
    "Use the difference in DIC between Models 1 and 2 to conclude something about the relative fitness of the two models.\n",
    "\n",
    "Then compute the Bayes factor and conclude something about the relative probability of the two models given the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Bonus Problem\n",
    "\n",
    "Use `emcee`'s parallel tempering functionality to calculate the log-evidences for the two models above (see the [documentation](http://dan.iel.fm/emcee/current/user/pt/)). Compare the difference in log-evidence with what you found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
