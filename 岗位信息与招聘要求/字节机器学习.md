字节-机器学习训练框架研发专家（豆包大模型）
1、负责字节跳动机器学习训练框架的研究与开发，服务于全公司各个产品；
2、参与机器学习训练框架底层组件的抽象，设计，优化与落地；
3、与全公司算法部门深度合作，为重点项目进行算法与系统的联合优化。
职位要求
1、熟练掌握Linux环境下的C/C++与Python语言；
2、接触过至少一种机器学习框架（Tensorflow / PyTorch / MxNet 或其他自研框架）；
3、有以下至少一项的背景知识与经验：GPU编程，编译器，高性能网络，分布式存储，集群调度；
4、具有独立解决问题的能力，良好的团队合作精神；
5、有强烈的工作责任心，较好的学习能力、沟通能力和自驱力；
6、有良好的工作文档习惯，及时按要求撰写更新工作流程及技术文档。

加分项：
1、深入研究过至少一种机器学习框架（Tensorflow / PyTorch / MxNet 或其他自研框架）的底层架构和机制；
2、熟悉至少一种经典深度学习模型及其应用场景，如ResNet50，BERT，或者了解GAN，强化学习，图神经网络，AutoML等；
3、有硕士研究生或博士研究生阶段的计算机系统方向（包含分布式系统，并行计算，编程语言与编译器，网络，存储等）研究背景；
4、有软硬件联合设计的经验；
5、能使用数学工具分析深度学习训练中的优化算法。


字节机器学习系统调度专家-豆包大模型
1、负责机器学习系统资源调度的设计和开发，服务于各方向场景（NLP/CV/Speech等）的模型训练、模型评估和模型推理；
2、负责多种异构资源（GPU、CPU、其他异构硬件）的最优化编排，实现稳定资源、潮汐资源、混布资源、多云资源的合理化使用；
3、负责通过技术手段实现计算资源、RDMA高速网络资源、存储资源的最优调度，充分发挥大规模分布式集群的计算能力；
4、负责多机房、多地域、多云场景的在离线任务/服务调度，实现全球负载的合理化分布。
职位要求
1、熟练掌握Linux环境下的Go/Python/Shell等1至2种以上语言；
2、熟悉 Kubernetes 架构和生态，熟悉 Docker/Containerd/Kata/Podman 等容器技术，有丰富的机器学习系统实践和开发经验；
3、掌握分布式系统原理，参与过大规模分布式系统的设计、开发和维护；
4、有优秀的逻辑分析能力，能够对业务逻辑进行合理的抽象和拆分；
5、有强烈的工作责任心，较好的学习能力、沟通能力和自驱力，能够快速的响应和行动；
6、有良好的工作文档习惯，及时按要求撰写更新工作流程及技术文档。
加分项：
1、熟悉至少一种主流的机器学习框架（TensorFlow / PyTorch ）；
2、有以下某一方向领域的经验：AI Infrastructure，HW/SW Co-Design，High Performance Computing，ML Hardware Architecture (GPU, Accelerators, Networking)。
字节—机器学习系统推理引擎资深工程师/专家-豆包大模型

1、以自研推理引擎为中心的在线推理服务和近离线批式推理任务框架，负责超大规模机器学习系统架构的设计开发，解决系统高并发、高可靠性、高可扩展性等技术难关，为搜索、推荐、审核等业务提供深度模型推理全场景端到端解决方案；
2、针对PyTorch、TensorFlow等框架提供高自动化、极致性能的模型优化方案，技术方案不限于子图匹配、编译优化、模型量化、异构硬件等；
3、面向全球多地域超大规模GPU算力集群，通过弹性调度、GPU 超卖、任务编排等方式不断提升算力利用率；
4、与算法部门深度合作，进行算法与系统的联合优化。
职位要求
1、熟练掌握Linux环境下的C/C++与Python语言，有大规模机器学习系统或搜广推推荐系统相关经验；
2、熟悉至少一种机器学习框架（Tensorflow / PyTorch / MxNet 或其他自研框架）；
3、有以下至少一项的背景知识与经验：GPU 编程、编译器、模型量化、GPU 集群调度；
4、具有独立解决问题的能力，良好的团队合作精神，具备优秀的复杂问题拆解能力；
5、有强烈的工作责任心，较好的学习能力、沟通能力和自驱力；
6、有良好的工作文档习惯，及时按要求撰写更新工作流程及技术文档。

加分项：
1、有推荐/广告/搜索离在线推理系统架构经验；
2、理解 GPU硬件架构，理解GPU软件栈（CUDA，cuDNN)，具备GPU性能分析的经验。


字节AML-机器学习系统研发工程师
1、负责火山引擎机器学习训练和推理框架的研发和性能优化，支撑火山引擎机器学习平台和方舟大模型平台的相关需求和架构迭代；
2、负责解决系统高并发、高可靠性、高可扩展性等技术难关；
3、覆盖机器学习系统多个子方向领域的工作，包括：资源调度、任务编排、模型训练、模型推理、模型管理、数据集管理、工作流编排、ML for System等；
4、负责机器学习系统前瞻技术的调研和引入，比如：最新硬件架构、异构计算系统、GPU 优化技术的引入落地；
5、研究基于机器学习方法，实现对集群/服务资源使用情况的分析和优化。
职位要求
1、有C/C++/Python/Cuda开发经验，熟练使用Linux 系统/ GDB /Nsight等工具，ACM/ICPC/Codeforces等获奖者优先；
2、能够从产品思维、机器性能和稳定性、团队协作等多种视角，高标准要求自己的技术方案和每一行代码；
3、对如下一个或多个领域有经验，或者无经验但有浓厚的兴趣（须额外付出自己的时间进行深入研究和探索）：
a. 大模型系统：基础模型的分布式训练（Scaling Laws）、高效微调（Lora/P-Tuning/RLHF）、推理引擎和优化（并行策略、量化压缩、算子优化等）、Transformer模型结构(Sparse/MoE/LongContext等)；
b. AI+HPC：并行计算(CPU/Cuda/OpenCL)、通信(NCCL/MPI/RDMA/DPDK)、AI编译器(MLIR/TVM/Trition/LLVM)、Linux OS及Kernel；
c. 机器学习算法：各类基于梯度的经典算法与经典模型(ResNet/BERT/GPT/Swin Transformer/MLP-Mixer）、多模态(CLIP/BLIP/miniGPT4)。

AML-机器学习平台研发工程师
1、负责AML-机器学习平台的开发与优化，打造国内领先的聚焦AI开发者体验的机器学习平台；
2、从机器学习系统架构、云原生架构、公有云架构，等多个层面，进行技术探索和攻坚，帮助客户实现高性能、高资源利用率的高性能计算平台。
职位要求
1、计算机相关专业本科及以上学历，两年以上Linux Golang/C/C++/Python/Java的开发经验；
2、有实际的大规模分布式系统相关工作经历优先；
3、对如下一个或多个领域有浓厚的兴趣，并愿意付出自己的时间进行深入研究和探索：
1）机器学习框架：Pytorch等机器学习框架、GPU等异构计算芯片及优化、MLOps、CV/NLP/搜广推等领域模型算法等；
2）云原生：Kubernetes及容器系统、大规模训练任务和推理服务编排和调度、镜像加速等；
3）公有云：云存储、网络虚拟化、云安全、技术商品化探索等。

